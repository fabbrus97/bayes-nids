import argparse
import pandas as pd
import os

ROW_PER_FILE = 15000

def convert_port(data):
    port = 0
    try:
        port = int(data)
    except:
        pass
    return port

def load_with_pandas(label, input_path, output_path):
    
    files = os.listdir(os.path.join(input_path, "argus"))
    nfiles = len(files)
    current_file = 1
    df_all = pd.DataFrame()
    for filename in files:
        print("current_file:", current_file, "/", nfiles, filename)
        current_file += 1
        if not filename.endswith(".csv"):
            print("\nfile skipped")
            continue
    
        zfilename = filename.replace("-argus", "-zeek")
        zeek_df = pd.pandas.read_csv(os.path.join(input_path, "zeek", zfilename), names=["uid","ts","is_sm_ips_ports","ct_state_ttl","ct_flw_http_mthd","is_ftp_login","ct_ftp_login","ct_srv_src","ct_srv_dst","ct_dst_ltm","ct_src_ltm","ct_src_dport_ltm","ct_dst_sport_ltm","ct_dst_src_ltm"], dtype={"ts": 'float64'})
        # print(zeek_df.head())
        

        zeek_df_grp = zeek_df.groupby('uid', group_keys=True, sort=False).max()
        # print(zeek_df_grp)

        argus_df = pd.pandas.read_csv(os.path.join(input_path, "argus", filename), header=0,
                converters = {'Sport': convert_port, 'Dport': convert_port},
                dtype={'StartTime':'float64','LastTime':'float64'})
        # print(argus_df)
        
        df = argus_df.merge(zeek_df_grp, how="inner", left_on="LastTime", right_on="ts").sort_values("LastTime").drop("ts", axis=1)
        

        #    DATA TRANSFORMATION
        #from categorical data to enum ("tcp", "udp", "icmp",... => 1,2,3,...)
        #remove NaN from numerical data
        
        #TODO and between features?

        df['sTtl'] = df['sTtl'].fillna(0)
        df['dTtl'] = df['dTtl'].fillna(0)
        df['SrcWin'] = df['SrcWin'].fillna(0)
        df['DstWin'] = df['DstWin'].fillna(0)
        df['SrcTCPBase'] = df['SrcTCPBase'].fillna(0)
        df['TcpRtt'] = df['TcpRtt'].fillna(0)
        df['DstTCPBase'] = df['DstTCPBase'].fillna(0)
        df['SrcJitter'] = df['SrcJitter'].fillna(0)
        df['DstJitter'] = df['DstJitter'].fillna(0)
        df['SIntPkt'] = df['SIntPkt'].fillna(0)
        df['DIntPkt'] = df['DIntPkt'].fillna(0) 
        df['Trans'] = df['Trans'].fillna(0)
        df['Min'] = df['Min'].fillna(0)
        df['Max'] = df['Max'].fillna(0)
        df['Sum'] = df['Sum'].fillna(0)
        df['Sport'] = df['Sport'].fillna(0)
        df['Dport'] = df['Dport'].fillna(0)
        
        #l = 0
        #if label == "attack":
        #    l = 1
        #df.insert(df.shape[1], "label", [l]*df.shape[0])
        df.insert(df.shape[1], "label", [label]*df.shape[0])

        for key in ["SrcBytes", "DstBytes", "SrcLoad", "DstLoad", "SrcJitter", "DstJitter", "SIntPkt", "DIntPkt", "TcpRtt", "SynAck", "AckDat"]:
            if df[key].empty:
                print("cannot compute quantile for key", key, "empty axis")
                continue
            #binnig by quantile - each bin has the same amount of rows; we use  bins
            df[key] = pd.qcut(df[key], q=[0, .25, .5, .75, 1.], duplicates="drop", labels=False)

        
        # print(df.head())
        #if df_all.count().empty:
        #    df_all = df
        #else:
        #    df_all = pd.concat([df_all, df])
        df.to_csv(f"{output_path}/raw_traffic_{label}.{index}.csv", index=False)
    

    # df_all['SrcAddr'] = pd.factorize(df['SrcAddr'])[0]
    # df_all['DstAddr'] = pd.factorize(df['DstAddr'])[0]
    # df_all['Sport'] = pd.factorize(df['Sport'])[0] #to eliminate NaN values
    # df_all['Dport'] = pd.factorize(df['Dport'])[0] #to eliminate NaN values
    # df_all['Proto'] = pd.factorize(df['Proto'])[0]
    
    df_all['State'] = pd.factorize(df_all['State'])[0]
    

    df_encoded = pd.get_dummies(df_all, columns=['SrcAddr', 'DstAddr', 'Proto', 'State'])

    start = 0
    index = 1
    df2write = df_encoded[start:start+ROW_PER_FILE]
    print("\nstart writing data...")
    while (df2write.shape[0] >= ROW_PER_FILE):
        df2write.to_csv(f"{output_path}/raw_traffic_{label}.{index}.csv", index=False)
        index += 1
        start += ROW_PER_FILE
        df2write = df_encoded[start:start+ROW_PER_FILE]
        print("written", start, "rows")
    df_encoded[start:].to_csv(f"{output_path}/raw_traffic_{label}.{index}.csv", index=False)

    # df.to_csv("pandas.csv", index=False)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        prog="preprocess_data.py",
        description="This script loads a folder that contains csv files generated by \
                    zeek and argus and merges them togheter."
    )
    parser.add_argument("--input_path", required=True)
    parser.add_argument("--output_path", required=True)
    parser.add_argument("--traffic_type", required=True, choices=['normal', 'attack'])

    args = parser.parse_args()

    load_with_pandas(args.traffic_type, args.input_path, args.output_path)
